---
title: Understanding the Spectrum of Procedural Generation in Game Art
date: 2026-01-16
tags: [Game, Art, Pipeline, AI]
published: true
excerpt: I wanted to understand the art pipeline.
---
For the longest time, I carried a fundamental misunderstanding about game development: I thought everything visual in a game needed to be drawn or modeled by hand. When I saw a beautiful indie game like Florence or Gris, I assumed every scene, every UI element, every particle effect was painstakingly created by an artist. This misconception kept me from fully understanding what was actually possible when building games, especially as a solo developer.

The breakthrough came during a conversation about making a Florence-like narrative game. I wanted to understand the art pipeline—how do you actually create all those beautiful scenes, the characters, the interactive elements? What I discovered fundamentally changed how I think about game art.

## The Spectrum of Generation

The key insight is that "procedural generation" isn't a binary switch—it's a spectrum. On one end, you have elements that absolutely require human artistic decision-making. On the other end, you have things that can be entirely generated by algorithms. And crucially, there's a massive middle ground where the two approaches blend together.

At the "cannot be procedurally generated" end, you find things that need genuine artistic intent and emotional expression. The main scene illustrations in Florence—the bedroom bathed in morning light, the coffee shop where two people meet—these require storytelling through composition. Each detail carries meaning. You might use AI to generate these (as I'm learning to do), or hire an artist, or draw them yourself, but you can't just write a function that outputs "a scene that makes players feel nostalgic warmth."

Moving along the spectrum, you reach semi-procedural territory. This is where you have a base asset created by a human or AI, and then use code to generate variations. Think of a character's different facial expressions: you might have one base design, then programmatically swap out mouth shapes and eye positions to create happy, sad, surprised versions. Or consider enemy variants in a roguelike—same base design, different colors and stats generated by code.

In the middle of the spectrum live rule-based graphics. These are shapes and forms that follow patterns, but those patterns need to be defined by a designer. A dialogue box with rounded corners, a heart-shaped particle, a puzzle piece with organic edges—these can all be drawn by code, but someone needs to write the rules. Here's where it gets interesting: even "hand-drawn style" elements can be procedurally generated. A perfect circle drawn by code feels mechanical, but add some Perlin noise to make the edges slightly irregular, apply a paper texture overlay, and suddenly it has that sketch-like quality that matches your hand-painted scenes.

Further along, you find purely algorithmic generation. Particle systems that simulate physics, flowers petals falling and rotating based on gravity and wind, ripples spreading across water—these follow mathematical and physical laws. No artistic decision needed for each individual particle; you're designing the system's behavior.

At the far end of the spectrum sits abstract mathematical art, where the entire work is the algorithm itself. Fractals, L-systems generating plant-like structures, terrain generated from noise functions. Games like Manifold Garden exist almost entirely in this space.

## What Actually Gets Procedurally Generated?

Understanding the spectrum is one thing, but what does this look like in practice? I was shocked to learn the actual ratios in real games.

For narrative-driven games like Florence or Journey, roughly thirty to forty percent of the visual elements are procedurally generated. All those particle effects—the light motes, the flower petals, the ambient atmosphere—those are code. Every UI element, from dialogue boxes to menu buttons, is drawn programmatically. Screen transitions, fades, the subtle animations that guide your eye—all procedural. What's hand-crafted are the key scene backgrounds, the character designs, and important narrative moments. The rest, despite looking cohesive and artistic, is generated.

Roguelikes flip this ratio entirely. Games like Hades or Dead Cells are seventy to eighty percent procedural. The main character design is hand-drawn, major bosses get custom art, but then everything else—the thousands of possible room layouts, enemy color variants, environmental details, all effects—is generated by algorithms combining hand-made building blocks in endless permutations.

Even pixel art games, which feel deeply hand-crafted, are typically twenty to thirty percent procedural. The pixel art itself is hand-placed, but particles, UI elements, and simple effects are still code-generated.

Modern AAA games might surprise you most. About half of what you see in massive open worlds is procedurally assisted. Artists don't hand-place every tree in a forest or model every building interior. They create the base assets and define rules for how they should be distributed, combined, and varied. Tools like Houdini have made this "procedural assistance" the industry standard.

## The Modern Solo Developer Workflow

This understanding completely changes what's possible for independent developers. Before 2020, if you wanted to make a game with a hundred unique cards, you either spent two hundred hours painting them, bought asset packs, or found a collaborator. Now, you can generate a hundred illustrations with AI in five hours, use a Python script to batch process them in two hours, and write code to procedurally generate the card frames and UI in three hours. Ten hours total instead of two hundred.

The new golden ratio for indie development seems to be: thirty percent AI-generated core art, twenty percent manual refinement of those generations, thirty percent procedural generation for UI and effects, and twenty percent from asset stores for things like fonts and sound effects. This means you can spend maybe twenty percent of your development time on art instead of sixty percent, freeing up time for gameplay, narrative, and polish.

## Building a Florence-Like Game: A Practical Pipeline

When I started planning my own narrative game, understanding this spectrum helped me see the actual path forward. For five key scenes, I don't need to become an illustrator. I can use AI to generate them, spending a few hours testing prompts and selecting the best results. The crucial part is establishing a visual style anchor—one good generation that defines the color palette, the artistic approach, the mood. Everything else references back to this anchor.

For character consistency across different poses and expressions, I learned there are specific techniques: generating a character sheet with multiple views in one image, or using that first successful character generation as a style reference for all future generations. The goal isn't pixel-perfect consistency (even Florence's characters vary slightly between scenes) but maintaining recognizable identity.

The interactive elements—the puzzle pieces, the dialogue bubbles, the minigame interfaces—these are where procedural generation shines. I extract the color palette from my AI-generated scenes (usually five to eight core colors) and use only those colors in my code-generated UI. I add slight irregularity to shapes so they don't feel too perfect and mechanical. I might generate a paper texture once with AI and overlay it on all programmatic elements at low opacity, instantly giving everything a unified hand-drawn feel.

Special effects like heart particles or falling petals occupy a middle ground. I might have AI generate one petal sprite, then write code to make hundreds of them fall, rotate, and fade with physics simulation. The base asset is "artistic" but its behavior is entirely algorithmic.

## The Shift in Understanding

What I realized through all of this is that my fundamental question was wrong. I kept asking "how do I learn to make game art?" when I should have been asking "what parts actually need to be art, and what parts can be systems?"

A dialogue box doesn't need to be painted—it needs to be designed once, then generated consistently by code. A particle effect doesn't need frame-by-frame animation—it needs physics rules. A hundred enemy variants don't need individual illustrations—they need a base design and a system for creating variations.

This doesn't diminish the importance of artistic vision. If anything, it clarifies where artistic decisions matter most. You're not spending time manually creating the fiftieth variation of a background tree. You're spending time on the composition of that key emotional scene, on the character design that carries your narrative, on the visual style that makes your game recognizable.

The tools available in 2025—AI for generating base art, simple scripting for batch processing, powerful procedural systems in game engines, abundant free resources—mean that technical limitations barely exist anymore. The limitation is understanding what's possible, knowing which tool to reach for, recognizing which problems have already been solved by systems rather than manual work.

I started this conversation thinking I was missing some fundamental knowledge, some systematic understanding of computer science that would unlock game development. What I actually needed was to understand this spectrum, to know that most of what looks like painstaking artistic work is actually clever systems design. The art in modern game development isn't just in the pixels—it's in knowing how to combine human creativity, AI assistance, and procedural systems into something cohesive.

For anyone else feeling lost in the space between "I know some programming" and "I can make the games I imagine," this might be your missing piece too. Not everything needs to be drawn. Most things can be generated. The question is just understanding which is which, and how to make them work together.